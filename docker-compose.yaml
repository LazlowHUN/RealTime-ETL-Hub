services:
  kafka:
    image: confluentinc/cp-kafka:7.8.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_BROKER_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      CLUSTER_ID: 'EmptNWtoR4GGWx-BH6nGLQ'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - kafkanet

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-cluster-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      - kafka
    networks:
      - kafkanet

  etl-producer:
    container_name: etl-producer
    build:
      context: .
      dockerfile: Dockerfile.etl
    env_file:
      - .env
    depends_on:
      - kafka
    command: ["python", "/app/kafka_clients/producer.py"]
    networks:
      - kafkanet

  etl-consumer:
    container_name: etl-consumer
    build:
      context: .
      dockerfile: Dockerfile.etl
    env_file:
      - .env
    depends_on:
      - kafka
    command: ["python", "/app/kafka_clients/consumer.py"]
    networks:
      - kafkanet

  postgres:
    image: postgres:15
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    networks:
      - kafkanet

  airflow:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow
    restart: always
    ports:
      - "8081:8080"
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__LOGGING__REMOTE_LOGGING: "False"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./dbt_project:/dbt_project
      - ./dbt_project/profiles.yml:/home/airflow/.dbt/profiles.yml
    depends_on:
      - postgres
      - kafka
    command: >
      bash -c "airflow db init && \
               airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin && \
               airflow webserver"
    networks:
      - kafkanet

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-scheduler
    restart: always
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__LOGGING__REMOTE_LOGGING: "False"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./dbt_project:/dbt_project
      - ./dbt_project/profiles.yml:/home/airflow/.dbt/profiles.yml
    depends_on:
      - airflow
    command: scheduler
    networks:
      - kafkanet

networks:
  kafkanet:
    driver: bridge
